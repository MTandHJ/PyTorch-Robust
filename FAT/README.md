


## FAT

> [Zhang J., Xu X., Han B., Niu G., Cui L., Sugiyama M.,  Kankanhalli M. Attacks which do not kill training make adversarial learning stronger. In International Conference on Machine Learning (ICML), 2020.](http://arxiv.org/abs/2002.11242)

[official-code](https://github.com/zjfheart/Friendly-Adversarial-Training)


### CIFAR-10

	python AT.py resnet18 cifar10 --attack=fpgd-linf -lp=FAT
	python TRADES.py resnet18 cifar10 --attack=fpgd-linf -lp=FAT-TRADES




